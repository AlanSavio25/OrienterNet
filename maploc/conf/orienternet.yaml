defaults:
  - data: mapillary
  - model/image_encoder: resnet_fpn
  - training
  - _self_
model:
  name: orienternet
  latent_dim: 128
  matching_dim: 8
  pixel_per_meter: ${data.pixel_per_meter}
  num_rotations: 64
  image_encoder:
    backbone:
      encoder: resnet101
  map_encoder:
    embedding_dim: 16
    output_dim: ${..matching_dim}
    num_classes: ${data.num_classes}
    scale_factor:
    backbone:
      encoder: vgg19
      pretrained: false
      output_scales: [0]
      num_downsample: 3
      decoder: [128, 64, 64]
      padding: replicate
    unary_prior: false
  # aerial_encoder:
  #   backbone:
  #     encoder: resnet50
  #     remove_stride_from_first_conv: true
  #     output_dim: ${...matching_dim}
  #   # unary_prior: true
  bev_mapper:
    image_encoder:
      backbone:
        encoder: resnet101
    scale_classifier: mlp
    scale_mlp:
      activation: ReLU
      layers:
        - ${...num_scale_bins}
      apply_input_activation: true
      input_dim: ${...latent_dim}
    fusion_mlp: # fuses feature with depth score
      activation: ReLU
      layers:
        - ${eval:'${...latent_dim}*2'}
        - ${...latent_dim}
      apply_input_activation: false
      input_dim: ${eval:'${...latent_dim} + 1'}
    mode: inverse
    z_min: 1.0
    z_max: # 32.0 # depth
    x_max: # 32.0
    grid_height: 12
    grid_cell_size: ${eval:'1/${..pixel_per_meter}'} # 0.5
    grid_z_offset_range: [-1.5, 1.5]
    pixel_per_meter: ${..pixel_per_meter}
    num_scale_bins: 33
    num_rotations: ${..num_rotations}
    latent_dim: ${..latent_dim}
    feature_depth_fusion: mlp
    vertical_pooling: max # max, mean, sum
    bev_net:
      num_blocks: 4
      latent_dim: ${...latent_dim}
      output_dim: ${...matching_dim}
      confidence: true
  ransac_matcher: false
  chop_bev: false
  normalize_features: false
